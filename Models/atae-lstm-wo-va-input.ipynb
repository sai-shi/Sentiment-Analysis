{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "iterations = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "reg_eta = 0.001\n",
    "\n",
    "# dimensionalities\n",
    "dim_lstm = 300\n",
    "dim_word = 300\n",
    "dim_aspect = 5\n",
    "dim_aspect_embedding = 300\n",
    "dim_sentence = 80\n",
    "dim_polarity = 3\n",
    "\n",
    "# setup utils object\n",
    "u = utils.UTILS(batch_size, dim_sentence, dim_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tf placeholders\n",
    "X = tf.placeholder(tf.int32, [None, dim_sentence])\n",
    "y = tf.placeholder(tf.float32, [None, dim_polarity])\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "aspects = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# define tf variables\n",
    "with tf.variable_scope('aspect_embedding_vars', reuse = tf.AUTO_REUSE):\n",
    "    va = tf.get_variable(\n",
    "        name = 'aspect_matrix_Va',\n",
    "        shape = [dim_aspect, dim_aspect_embedding],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "    wv = tf.get_variable(\n",
    "        name = 'aspect_Wv',\n",
    "        shape = [dim_aspect_embedding, dim_aspect_embedding],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "with tf.variable_scope('attention_vars', reuse = tf.AUTO_REUSE):\n",
    "    wh = tf.get_variable(\n",
    "        name = 'M_tanh_Wh',\n",
    "        shape = [dim_lstm, dim_lstm],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "    w = tf.get_variable(\n",
    "        name = 'alpha_softmax_W',\n",
    "        shape = [dim_lstm + dim_aspect_embedding, 1],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "    wp = tf.get_variable(\n",
    "        name = 'hstar_tanh_Wp',\n",
    "        shape = [dim_lstm, dim_lstm],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "    wx = tf.get_variable(\n",
    "        name = 'hstar_tanh_Wx',\n",
    "        shape = [dim_lstm, dim_lstm],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "with tf.variable_scope('output_softmax_vars', reuse = tf.AUTO_REUSE):\n",
    "    ws = tf.get_variable(\n",
    "        name = 'y_softmax_Ws',\n",
    "        shape = [dim_lstm, dim_polarity],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )\n",
    "    bs = tf.get_variable(\n",
    "        name = 'y_softmax_Bs',\n",
    "        shape = [dim_polarity],\n",
    "        initializer = tf.random_normal_initializer(0, 0.003),\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(reg_eta)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lstm model\n",
    "def dynamic_lstm(inputs, seqlen, aspects):\n",
    "    inputs = tf.nn.dropout(inputs, keep_prob=1.0)\n",
    "    with tf.name_scope('lstm_model'):\n",
    "        # slice the corresponding vai from va\n",
    "        vai = tf.gather(va, aspects) # batch_size x dim_aspect_embedding\n",
    "        lstm_cell = tf.contrib.rnn.LSTMCell(dim_lstm)\n",
    "        H, state = tf.nn.dynamic_rnn(\n",
    "            lstm_cell,\n",
    "            inputs = inputs,\n",
    "            sequence_length = seqlen,\n",
    "            dtype = tf.float32,\n",
    "            scope = 'lstm'\n",
    "        )\n",
    "        size = tf.shape(H)[0]\n",
    "        wv_vai = tf.matmul(vai, wv) # batch_size x dim_aspect_embedding\n",
    "        # stacking Wv x Va along sentence length\n",
    "        wv_vai = [wv_vai for i in range(dim_sentence)]\n",
    "        wv_vai_en = tf.stack(wv_vai, axis = 1) # batch_size x dim_sentence x dim_aspect_embedding\n",
    "        wv_vai_en = tf.reshape(wv_vai_en, [-1, dim_aspect_embedding]) # (batch_size * dim_sentence) x dim_aspect_embedding\n",
    "        H_1 = tf.reshape(H, [-1, dim_lstm]) # (batch_size * dim_sentence) x dim_lstm\n",
    "        wh_H = tf.matmul(H_1, wh) # (batch_size * dim_sentence) x dim_lstm\n",
    "        # concatenate wh_H and wv_va_En for inputting to tanh\n",
    "        wh_H_wv_vai_en = tf.concat([wh_H, wv_vai_en], 1) # (batch_size * dim_sentence) x (dim_lstm + dim_aspect_embedding)\n",
    "        M = tf.tanh(wh_H_wv_vai_en) # (batch_size * dim_sentence) x (dim_lstm + dim_aspect_embedding)\n",
    "        alpha = tf.nn.softmax(tf.matmul(M, w)) # (batch_size * dim_sentence)\n",
    "        alpha = tf.reshape(alpha, [-1, 1, dim_sentence]) # batch_size x 1 x dim_sentence\n",
    "        index = tf.range(0, size) * dim_sentence + seqlen - 1 # batch_size\n",
    "        hn = tf.gather(tf.reshape(H, [-1, dim_lstm]), index)  # batch_size x dim_lstm\n",
    "        r = tf.reshape(tf.matmul(alpha, H), [-1, dim_lstm]) # batch_size x dim_lstm\n",
    "        h_star = tf.tanh(tf.matmul(r, wp) + tf.matmul(hn, wx)) # batch_size x dim_lstm\n",
    "        predict = tf.matmul(h_star, ws) + bs # batch x dim_polarity\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# define operations\n",
    "# tf.reset_default_graph()\n",
    "pred = dynamic_lstm(tf.nn.embedding_lookup(u.gloveDict, X), seqlen, aspects)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 1.0188078, train accuracy: 0.6196703\n",
      "step: 0, test loss: 0.9933252, test accuracy: 0.6752312\n",
      "step: 1, train loss: 0.94880563, train accuracy: 0.6196703\n",
      "step: 1, test loss: 0.88048136, test accuracy: 0.6752312\n",
      "step: 2, train loss: 0.9366695, train accuracy: 0.6196703\n",
      "step: 2, test loss: 0.836337, test accuracy: 0.6752312\n",
      "step: 3, train loss: 0.9341613, train accuracy: 0.6196703\n",
      "step: 3, test loss: 0.8282824, test accuracy: 0.6752312\n",
      "step: 4, train loss: 0.9304846, train accuracy: 0.6196703\n",
      "step: 4, test loss: 0.83189875, test accuracy: 0.6752312\n",
      "step: 5, train loss: 0.9276022, train accuracy: 0.6196703\n",
      "step: 5, test loss: 0.8387933, test accuracy: 0.6752312\n",
      "step: 6, train loss: 0.9197108, train accuracy: 0.6196703\n",
      "step: 6, test loss: 0.83817595, test accuracy: 0.6752312\n",
      "step: 7, train loss: 0.914806, train accuracy: 0.619386\n",
      "step: 7, test loss: 0.83763844, test accuracy: 0.6752312\n",
      "step: 8, train loss: 0.91689193, train accuracy: 0.619386\n",
      "step: 8, test loss: 0.843333, test accuracy: 0.6752312\n",
      "step: 9, train loss: 0.9173068, train accuracy: 0.619386\n",
      "step: 9, test loss: 0.8479347, test accuracy: 0.6752312\n",
      "step: 10, train loss: 0.916164, train accuracy: 0.619386\n",
      "step: 10, test loss: 0.84910583, test accuracy: 0.6752312\n",
      "step: 11, train loss: 0.9112707, train accuracy: 0.619386\n",
      "step: 11, test loss: 0.8417736, test accuracy: 0.6752312\n",
      "step: 12, train loss: 0.9036266, train accuracy: 0.619386\n",
      "step: 12, test loss: 0.82682616, test accuracy: 0.6752312\n",
      "step: 13, train loss: 0.8955478, train accuracy: 0.619386\n",
      "step: 13, test loss: 0.81728655, test accuracy: 0.6752312\n",
      "step: 14, train loss: 0.8885765, train accuracy: 0.619386\n",
      "step: 14, test loss: 0.8045484, test accuracy: 0.6752312\n",
      "step: 15, train loss: 0.88281995, train accuracy: 0.619386\n",
      "step: 15, test loss: 0.79665583, test accuracy: 0.6752312\n",
      "step: 16, train loss: 0.87759316, train accuracy: 0.619386\n",
      "step: 16, test loss: 0.7940128, test accuracy: 0.6752312\n",
      "step: 17, train loss: 0.86961806, train accuracy: 0.619386\n",
      "step: 17, test loss: 0.7807037, test accuracy: 0.6752312\n",
      "step: 18, train loss: 0.85883915, train accuracy: 0.61910176\n",
      "step: 18, test loss: 0.77619517, test accuracy: 0.6752312\n",
      "step: 19, train loss: 0.84772253, train accuracy: 0.61910176\n",
      "step: 19, test loss: 0.76563853, test accuracy: 0.6752312\n",
      "step: 20, train loss: 0.83652663, train accuracy: 0.61910176\n",
      "step: 20, test loss: 0.7558642, test accuracy: 0.6752312\n",
      "step: 21, train loss: 0.8260236, train accuracy: 0.61910176\n",
      "step: 21, test loss: 0.75252783, test accuracy: 0.6752312\n",
      "step: 22, train loss: 0.8390415, train accuracy: 0.61910176\n",
      "step: 22, test loss: 0.7460823, test accuracy: 0.6752312\n",
      "step: 23, train loss: 0.8288659, train accuracy: 0.63274586\n",
      "step: 23, test loss: 0.764986, test accuracy: 0.69167525\n",
      "step: 24, train loss: 0.80276936, train accuracy: 0.65662307\n",
      "step: 24, test loss: 0.7382215, test accuracy: 0.7235355\n",
      "step: 25, train loss: 0.8216015, train accuracy: 0.6361569\n",
      "step: 25, test loss: 0.7284918, test accuracy: 0.6947585\n",
      "step: 26, train loss: 0.78133726, train accuracy: 0.66827744\n",
      "step: 26, test loss: 0.7040417, test accuracy: 0.7204522\n",
      "step: 27, train loss: 0.80474585, train accuracy: 0.6458215\n",
      "step: 27, test loss: 0.73873836, test accuracy: 0.6937307\n",
      "step: 28, train loss: 0.7649428, train accuracy: 0.675668\n",
      "step: 28, test loss: 0.6905439, test accuracy: 0.73175746\n",
      "step: 29, train loss: 0.78991497, train accuracy: 0.65918136\n",
      "step: 29, test loss: 0.69437706, test accuracy: 0.7183967\n",
      "step: 30, train loss: 0.7490445, train accuracy: 0.68249005\n",
      "step: 30, test loss: 0.66897684, test accuracy: 0.73586845\n",
      "step: 31, train loss: 0.76779234, train accuracy: 0.6776578\n",
      "step: 31, test loss: 0.6949045, test accuracy: 0.7245632\n",
      "step: 32, train loss: 0.7401519, train accuracy: 0.6910176\n",
      "step: 32, test loss: 0.6634986, test accuracy: 0.74614596\n",
      "step: 33, train loss: 0.75068223, train accuracy: 0.67168844\n",
      "step: 33, test loss: 0.6647202, test accuracy: 0.7266187\n",
      "step: 34, train loss: 0.72659796, train accuracy: 0.6938602\n",
      "step: 34, test loss: 0.64558333, test accuracy: 0.74717367\n",
      "step: 35, train loss: 0.7364362, train accuracy: 0.6827743\n",
      "step: 35, test loss: 0.66642517, test accuracy: 0.73175746\n",
      "step: 36, train loss: 0.71422035, train accuracy: 0.69613415\n",
      "step: 36, test loss: 0.64253914, test accuracy: 0.75025696\n",
      "step: 37, train loss: 0.72712624, train accuracy: 0.6904491\n",
      "step: 37, test loss: 0.64517474, test accuracy: 0.75128466\n",
      "step: 38, train loss: 0.6997525, train accuracy: 0.701535\n",
      "step: 38, test loss: 0.62556404, test accuracy: 0.76567316\n",
      "step: 39, train loss: 0.7151213, train accuracy: 0.6930074\n",
      "step: 39, test loss: 0.64559793, test accuracy: 0.73997945\n",
      "step: 40, train loss: 0.6896441, train accuracy: 0.70693576\n",
      "step: 40, test loss: 0.61737245, test accuracy: 0.7646454\n",
      "step: 41, train loss: 0.70324975, train accuracy: 0.6964184\n",
      "step: 41, test loss: 0.62463045, test accuracy: 0.7533402\n",
      "step: 42, train loss: 0.67983323, train accuracy: 0.71034676\n",
      "step: 42, test loss: 0.6079894, test accuracy: 0.76567316\n",
      "step: 43, train loss: 0.69134074, train accuracy: 0.7001137\n",
      "step: 43, test loss: 0.62106377, test accuracy: 0.7553957\n",
      "step: 44, train loss: 0.6721406, train accuracy: 0.7146106\n",
      "step: 44, test loss: 0.6009196, test accuracy: 0.76978415\n",
      "step: 45, train loss: 0.67713463, train accuracy: 0.70949405\n",
      "step: 45, test loss: 0.60450613, test accuracy: 0.7605344\n",
      "step: 46, train loss: 0.6663158, train accuracy: 0.7163161\n",
      "step: 46, test loss: 0.598164, test accuracy: 0.76978415\n",
      "step: 47, train loss: 0.6629042, train accuracy: 0.71660036\n",
      "step: 47, test loss: 0.5956, test accuracy: 0.7677287\n",
      "step: 48, train loss: 0.6590068, train accuracy: 0.7146106\n",
      "step: 48, test loss: 0.5928538, test accuracy: 0.76875645\n",
      "step: 49, train loss: 0.6478609, train accuracy: 0.7214326\n",
      "step: 49, test loss: 0.58431584, test accuracy: 0.78006166\n",
      "step: 50, train loss: 0.6514007, train accuracy: 0.7185901\n",
      "step: 50, test loss: 0.58889693, test accuracy: 0.76978415\n",
      "step: 51, train loss: 0.6357282, train accuracy: 0.7254122\n",
      "step: 51, test loss: 0.57466847, test accuracy: 0.78417265\n",
      "step: 52, train loss: 0.63362896, train accuracy: 0.7239909\n",
      "step: 52, test loss: 0.5728873, test accuracy: 0.7718397\n",
      "step: 53, train loss: 0.63198644, train accuracy: 0.72768617\n",
      "step: 53, test loss: 0.5737028, test accuracy: 0.77286744\n",
      "step: 54, train loss: 0.6156389, train accuracy: 0.73195\n",
      "step: 54, test loss: 0.56094605, test accuracy: 0.7903392\n",
      "step: 55, train loss: 0.6145487, train accuracy: 0.7325185\n",
      "step: 55, test loss: 0.5611934, test accuracy: 0.7903392\n",
      "step: 56, train loss: 0.6214113, train accuracy: 0.733087\n",
      "step: 56, test loss: 0.5718846, test accuracy: 0.7759507\n",
      "step: 57, train loss: 0.5987942, train accuracy: 0.74445707\n",
      "step: 57, test loss: 0.55164003, test accuracy: 0.79856116\n",
      "step: 58, train loss: 0.58725256, train accuracy: 0.75412166\n",
      "step: 58, test loss: 0.5441811, test accuracy: 0.79136693\n",
      "step: 59, train loss: 0.58525157, train accuracy: 0.757817\n",
      "step: 59, test loss: 0.5430275, test accuracy: 0.79445016\n",
      "step: 60, train loss: 0.5762753, train accuracy: 0.7603752\n",
      "step: 60, test loss: 0.53120005, test accuracy: 0.7975334\n",
      "step: 61, train loss: 0.5653785, train accuracy: 0.7689028\n",
      "step: 61, test loss: 0.5243527, test accuracy: 0.7934224\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d6c03fde9093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_seqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_aspects\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         if i > 0 and i % 4 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_seqlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_aspects\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# full dataset training\n",
    "test_X, test_y, test_seqlen, test_aspects = u.getData('test')\n",
    "train_X, train_y, train_seqlen, train_aspects = u.getData('train')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        sess.run(optimizer, feed_dict = {X: train_X, y: train_y, seqlen: train_seqlen, aspects: train_aspects})\n",
    "#         if i > 0 and i % 4 == 0:\n",
    "        loss_train, accuracy_train = sess.run([loss, accuracy], feed_dict = {X: train_X, y: train_y, seqlen: train_seqlen, aspects: train_aspects})\n",
    "        print('step: %s, train loss: %s, train accuracy: %s' % (i, loss_train, accuracy_train))\n",
    "        loss_test, accuracy_test = sess.run([loss, accuracy], feed_dict = {X: test_X, y: test_y, seqlen: test_seqlen, aspects: test_aspects})\n",
    "        print('step: %s, test loss: %s, test accuracy: %s' % (i, loss_test, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4, train loss: 1.0626603, train accuracy: 0.5\n",
      "step: 4, test loss: 1.064084, test accuracy: 0.60328877\n",
      "step: 8, train loss: 1.0036991, train accuracy: 0.59375\n",
      "step: 8, test loss: 0.96842396, test accuracy: 0.6382323\n",
      "step: 12, train loss: 0.97157586, train accuracy: 0.6875\n",
      "step: 12, test loss: 0.929753, test accuracy: 0.6115108\n",
      "step: 16, train loss: 1.0183179, train accuracy: 0.625\n",
      "step: 16, test loss: 1.2224764, test accuracy: 0.5272353\n",
      "step: 20, train loss: 0.9538225, train accuracy: 0.5625\n",
      "step: 20, test loss: 0.9015234, test accuracy: 0.58992803\n",
      "step: 24, train loss: 0.8981655, train accuracy: 0.53125\n",
      "step: 24, test loss: 0.79759854, test accuracy: 0.68859196\n",
      "step: 28, train loss: 0.9151036, train accuracy: 0.53125\n",
      "step: 28, test loss: 0.9973002, test accuracy: 0.62487155\n",
      "step: 32, train loss: 0.83227533, train accuracy: 0.59375\n",
      "step: 32, test loss: 0.8038069, test accuracy: 0.663926\n",
      "step: 36, train loss: 0.8009197, train accuracy: 0.59375\n",
      "step: 36, test loss: 0.7305893, test accuracy: 0.70606375\n",
      "step: 40, train loss: 0.98849875, train accuracy: 0.53125\n",
      "step: 40, test loss: 0.7729243, test accuracy: 0.68139774\n",
      "step: 44, train loss: 0.84354544, train accuracy: 0.59375\n",
      "step: 44, test loss: 0.7507261, test accuracy: 0.68139774\n",
      "step: 48, train loss: 0.6451029, train accuracy: 0.71875\n",
      "step: 48, test loss: 0.8123663, test accuracy: 0.6752312\n",
      "step: 52, train loss: 0.8191462, train accuracy: 0.78125\n",
      "step: 52, test loss: 0.791061, test accuracy: 0.672148\n",
      "step: 56, train loss: 1.0418546, train accuracy: 0.59375\n",
      "step: 56, test loss: 0.6264017, test accuracy: 0.76258993\n",
      "step: 60, train loss: 0.71152383, train accuracy: 0.6875\n",
      "step: 60, test loss: 0.8742463, test accuracy: 0.6125385\n",
      "step: 64, train loss: 0.8292028, train accuracy: 0.6875\n",
      "step: 64, test loss: 0.7637548, test accuracy: 0.68345326\n",
      "step: 68, train loss: 0.83191967, train accuracy: 0.65625\n",
      "step: 68, test loss: 0.67773366, test accuracy: 0.7225077\n",
      "step: 72, train loss: 0.76798284, train accuracy: 0.71875\n",
      "step: 72, test loss: 0.8086632, test accuracy: 0.6536485\n",
      "step: 76, train loss: 0.7622425, train accuracy: 0.59375\n",
      "step: 76, test loss: 0.8338273, test accuracy: 0.6279548\n",
      "step: 80, train loss: 0.63544244, train accuracy: 0.6875\n",
      "step: 80, test loss: 0.7785968, test accuracy: 0.69167525\n",
      "step: 84, train loss: 0.76933867, train accuracy: 0.6875\n",
      "step: 84, test loss: 0.6681614, test accuracy: 0.7389517\n",
      "step: 88, train loss: 0.6449125, train accuracy: 0.78125\n",
      "step: 88, test loss: 0.8616935, test accuracy: 0.6115108\n",
      "step: 92, train loss: 0.9289923, train accuracy: 0.375\n",
      "step: 92, test loss: 0.6248388, test accuracy: 0.76258993\n",
      "step: 96, train loss: 0.7913232, train accuracy: 0.65625\n",
      "step: 96, test loss: 0.75024456, test accuracy: 0.6906475\n",
      "step: 100, train loss: 0.98756397, train accuracy: 0.5625\n",
      "step: 100, test loss: 0.67997986, test accuracy: 0.7389517\n",
      "step: 104, train loss: 0.6971179, train accuracy: 0.75\n",
      "step: 104, test loss: 0.61434054, test accuracy: 0.76978415\n",
      "step: 108, train loss: 1.0516843, train accuracy: 0.625\n",
      "step: 108, test loss: 0.81237924, test accuracy: 0.6577595\n",
      "step: 112, train loss: 0.72324955, train accuracy: 0.6875\n",
      "step: 112, test loss: 0.5565906, test accuracy: 0.7975334\n",
      "step: 116, train loss: 0.6242643, train accuracy: 0.75\n",
      "step: 116, test loss: 0.63182324, test accuracy: 0.7492292\n",
      "step: 120, train loss: 0.68529516, train accuracy: 0.625\n",
      "step: 120, test loss: 0.7713126, test accuracy: 0.65056527\n",
      "step: 124, train loss: 0.60950595, train accuracy: 0.75\n",
      "step: 124, test loss: 0.66805875, test accuracy: 0.75025696\n",
      "step: 128, train loss: 0.860803, train accuracy: 0.59375\n",
      "step: 128, test loss: 0.5942733, test accuracy: 0.76567316\n",
      "step: 132, train loss: 0.5674629, train accuracy: 0.84375\n",
      "step: 132, test loss: 0.63795245, test accuracy: 0.7338129\n",
      "step: 136, train loss: 0.62551254, train accuracy: 0.71875\n",
      "step: 136, test loss: 0.66853434, test accuracy: 0.7204522\n",
      "step: 140, train loss: 0.5984286, train accuracy: 0.84375\n",
      "step: 140, test loss: 0.6267217, test accuracy: 0.742035\n",
      "step: 144, train loss: 0.8478974, train accuracy: 0.65625\n",
      "step: 144, test loss: 0.77638113, test accuracy: 0.6711202\n",
      "step: 148, train loss: 0.7064049, train accuracy: 0.65625\n",
      "step: 148, test loss: 0.59810996, test accuracy: 0.7718397\n",
      "step: 152, train loss: 0.45414817, train accuracy: 0.84375\n",
      "step: 152, test loss: 0.6160239, test accuracy: 0.7646454\n",
      "step: 156, train loss: 0.601545, train accuracy: 0.78125\n",
      "step: 156, test loss: 0.782698, test accuracy: 0.68139774\n",
      "step: 160, train loss: 0.69428396, train accuracy: 0.78125\n",
      "step: 160, test loss: 0.6397133, test accuracy: 0.7389517\n",
      "step: 164, train loss: 0.64008665, train accuracy: 0.75\n",
      "step: 164, test loss: 0.62600297, test accuracy: 0.7533402\n",
      "step: 168, train loss: 0.51432157, train accuracy: 0.78125\n",
      "step: 168, test loss: 0.64835787, test accuracy: 0.7183967\n",
      "step: 172, train loss: 0.7977705, train accuracy: 0.5625\n",
      "step: 172, test loss: 0.56873226, test accuracy: 0.77389514\n",
      "step: 176, train loss: 0.53571635, train accuracy: 0.75\n",
      "step: 176, test loss: 0.69155365, test accuracy: 0.7204522\n",
      "step: 180, train loss: 0.6327927, train accuracy: 0.71875\n",
      "step: 180, test loss: 0.6006749, test accuracy: 0.7595067\n",
      "step: 184, train loss: 0.6373838, train accuracy: 0.75\n",
      "step: 184, test loss: 0.61452556, test accuracy: 0.7348407\n",
      "step: 188, train loss: 0.40890133, train accuracy: 0.8125\n",
      "step: 188, test loss: 0.67577446, test accuracy: 0.7348407\n",
      "step: 192, train loss: 0.5860395, train accuracy: 0.78125\n",
      "step: 192, test loss: 0.57610804, test accuracy: 0.75847894\n",
      "step: 196, train loss: 0.54566884, train accuracy: 0.8125\n",
      "step: 196, test loss: 0.80395246, test accuracy: 0.6896197\n",
      "step: 200, train loss: 0.8596767, train accuracy: 0.65625\n",
      "step: 200, test loss: 0.84439933, test accuracy: 0.6855087\n",
      "step: 204, train loss: 0.4617233, train accuracy: 0.84375\n",
      "step: 204, test loss: 0.659785, test accuracy: 0.73175746\n",
      "step: 208, train loss: 0.6647848, train accuracy: 0.71875\n",
      "step: 208, test loss: 0.65261143, test accuracy: 0.71531343\n",
      "step: 212, train loss: 0.5655329, train accuracy: 0.6875\n",
      "step: 212, test loss: 0.5455372, test accuracy: 0.78006166\n",
      "step: 216, train loss: 0.40655208, train accuracy: 0.90625\n",
      "step: 216, test loss: 0.6676138, test accuracy: 0.705036\n",
      "step: 220, train loss: 0.46816525, train accuracy: 0.84375\n",
      "step: 220, test loss: 0.7282395, test accuracy: 0.69578624\n",
      "step: 224, train loss: 0.41981745, train accuracy: 0.78125\n",
      "step: 224, test loss: 0.54197335, test accuracy: 0.7903392\n",
      "step: 228, train loss: 0.52642107, train accuracy: 0.78125\n",
      "step: 228, test loss: 0.6433565, test accuracy: 0.7266187\n",
      "step: 232, train loss: 0.423329, train accuracy: 0.875\n",
      "step: 232, test loss: 0.5761505, test accuracy: 0.75436795\n",
      "step: 236, train loss: 0.4101354, train accuracy: 0.875\n",
      "step: 236, test loss: 0.55817175, test accuracy: 0.76978415\n",
      "step: 240, train loss: 0.6309111, train accuracy: 0.75\n",
      "step: 240, test loss: 0.5388844, test accuracy: 0.76875645\n",
      "step: 244, train loss: 0.64628637, train accuracy: 0.71875\n",
      "step: 244, test loss: 0.56693184, test accuracy: 0.7595067\n",
      "step: 248, train loss: 0.42445803, train accuracy: 0.8125\n",
      "step: 248, test loss: 0.84570056, test accuracy: 0.668037\n",
      "step: 252, train loss: 0.37220496, train accuracy: 0.875\n",
      "step: 252, test loss: 0.61558527, test accuracy: 0.7790339\n",
      "step: 256, train loss: 0.6371258, train accuracy: 0.71875\n",
      "step: 256, test loss: 0.7025905, test accuracy: 0.73586845\n",
      "step: 260, train loss: 0.67061055, train accuracy: 0.625\n",
      "step: 260, test loss: 0.6013287, test accuracy: 0.76875645\n",
      "step: 264, train loss: 0.47565654, train accuracy: 0.78125\n",
      "step: 264, test loss: 0.5814609, test accuracy: 0.7646454\n",
      "step: 268, train loss: 0.51540554, train accuracy: 0.84375\n",
      "step: 268, test loss: 0.6726595, test accuracy: 0.7225077\n",
      "step: 272, train loss: 0.7261516, train accuracy: 0.625\n",
      "step: 272, test loss: 0.655447, test accuracy: 0.7368962\n",
      "step: 276, train loss: 0.6099224, train accuracy: 0.78125\n",
      "step: 276, test loss: 0.55905974, test accuracy: 0.7831449\n",
      "step: 280, train loss: 0.48689157, train accuracy: 0.84375\n",
      "step: 280, test loss: 0.590212, test accuracy: 0.7636177\n",
      "step: 284, train loss: 0.5374055, train accuracy: 0.75\n",
      "step: 284, test loss: 0.6594453, test accuracy: 0.7348407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 288, train loss: 0.6384232, train accuracy: 0.75\n",
      "step: 288, test loss: 0.59275424, test accuracy: 0.7553957\n",
      "step: 292, train loss: 0.549507, train accuracy: 0.8125\n",
      "step: 292, test loss: 0.6877318, test accuracy: 0.7194245\n",
      "step: 296, train loss: 0.34573045, train accuracy: 0.90625\n",
      "step: 296, test loss: 0.64270097, test accuracy: 0.7451182\n",
      "step: 300, train loss: 0.36133945, train accuracy: 0.90625\n",
      "step: 300, test loss: 0.56728935, test accuracy: 0.7790339\n",
      "step: 304, train loss: 0.7867471, train accuracy: 0.65625\n",
      "step: 304, test loss: 0.77320266, test accuracy: 0.692703\n",
      "step: 308, train loss: 0.3472127, train accuracy: 0.84375\n",
      "step: 308, test loss: 0.6192323, test accuracy: 0.75128466\n",
      "step: 312, train loss: 0.40323606, train accuracy: 0.8125\n",
      "step: 312, test loss: 0.5429678, test accuracy: 0.7893114\n",
      "step: 316, train loss: 0.81591547, train accuracy: 0.78125\n",
      "step: 316, test loss: 0.5857284, test accuracy: 0.76875645\n",
      "step: 320, train loss: 0.56856173, train accuracy: 0.8125\n",
      "step: 320, test loss: 0.60724205, test accuracy: 0.7605344\n",
      "step: 324, train loss: 0.42632744, train accuracy: 0.84375\n",
      "step: 324, test loss: 0.5803638, test accuracy: 0.7636177\n",
      "step: 328, train loss: 0.5297947, train accuracy: 0.84375\n",
      "step: 328, test loss: 0.5379708, test accuracy: 0.7934224\n",
      "step: 332, train loss: 0.46431386, train accuracy: 0.875\n",
      "step: 332, test loss: 0.52735853, test accuracy: 0.7995889\n",
      "step: 336, train loss: 0.64717233, train accuracy: 0.71875\n",
      "step: 336, test loss: 0.6038534, test accuracy: 0.76978415\n",
      "step: 340, train loss: 0.60986114, train accuracy: 0.875\n",
      "step: 340, test loss: 0.5492724, test accuracy: 0.79136693\n",
      "step: 344, train loss: 0.4371202, train accuracy: 0.84375\n",
      "step: 344, test loss: 0.56920755, test accuracy: 0.78006166\n",
      "step: 348, train loss: 0.2891568, train accuracy: 0.90625\n",
      "step: 348, test loss: 0.64454246, test accuracy: 0.75128466\n",
      "step: 352, train loss: 0.50268567, train accuracy: 0.78125\n",
      "step: 352, test loss: 0.6618723, test accuracy: 0.73997945\n",
      "step: 356, train loss: 0.5359304, train accuracy: 0.71875\n",
      "step: 356, test loss: 0.539659, test accuracy: 0.7995889\n",
      "step: 360, train loss: 0.5575492, train accuracy: 0.71875\n",
      "step: 360, test loss: 0.56836534, test accuracy: 0.77697843\n",
      "step: 364, train loss: 0.50080657, train accuracy: 0.78125\n",
      "step: 364, test loss: 0.60237896, test accuracy: 0.76875645\n",
      "step: 368, train loss: 0.5705017, train accuracy: 0.78125\n",
      "step: 368, test loss: 0.5520778, test accuracy: 0.7862282\n",
      "step: 372, train loss: 0.28191805, train accuracy: 0.90625\n",
      "step: 372, test loss: 0.5944012, test accuracy: 0.76978415\n",
      "step: 376, train loss: 0.49602515, train accuracy: 0.78125\n",
      "step: 376, test loss: 0.62555695, test accuracy: 0.7564234\n",
      "step: 380, train loss: 0.48935592, train accuracy: 0.75\n",
      "step: 380, test loss: 0.5892995, test accuracy: 0.7831449\n",
      "step: 384, train loss: 0.37504464, train accuracy: 0.8125\n",
      "step: 384, test loss: 0.6331231, test accuracy: 0.7667009\n",
      "step: 388, train loss: 0.7653004, train accuracy: 0.59375\n",
      "step: 388, test loss: 0.7226047, test accuracy: 0.7122302\n",
      "step: 392, train loss: 0.51965326, train accuracy: 0.75\n",
      "step: 392, test loss: 0.61793756, test accuracy: 0.7574512\n",
      "step: 396, train loss: 0.4253442, train accuracy: 0.84375\n",
      "step: 396, test loss: 0.57809013, test accuracy: 0.7677287\n",
      "step: 400, train loss: 0.3285793, train accuracy: 0.875\n",
      "step: 400, test loss: 0.6299538, test accuracy: 0.7564234\n",
      "step: 404, train loss: 0.36748564, train accuracy: 0.84375\n",
      "step: 404, test loss: 0.5981118, test accuracy: 0.7646454\n",
      "step: 408, train loss: 0.27651435, train accuracy: 0.90625\n",
      "step: 408, test loss: 0.6549927, test accuracy: 0.7379239\n",
      "step: 412, train loss: 0.37822282, train accuracy: 0.8125\n",
      "step: 412, test loss: 0.82262176, test accuracy: 0.69578624\n",
      "step: 416, train loss: 0.35374907, train accuracy: 0.84375\n",
      "step: 416, test loss: 0.6062033, test accuracy: 0.76258993\n",
      "step: 420, train loss: 0.57748073, train accuracy: 0.75\n",
      "step: 420, test loss: 0.7255399, test accuracy: 0.7183967\n",
      "step: 424, train loss: 0.37646192, train accuracy: 0.875\n",
      "step: 424, test loss: 0.6379129, test accuracy: 0.7523124\n",
      "step: 428, train loss: 0.35575137, train accuracy: 0.9375\n",
      "step: 428, test loss: 0.5847774, test accuracy: 0.7749229\n",
      "step: 432, train loss: 0.621833, train accuracy: 0.75\n",
      "step: 432, test loss: 0.7427958, test accuracy: 0.73997945\n",
      "step: 436, train loss: 0.37442073, train accuracy: 0.84375\n",
      "step: 436, test loss: 0.63820785, test accuracy: 0.7553957\n",
      "step: 440, train loss: 0.29498082, train accuracy: 0.8125\n",
      "step: 440, test loss: 0.5498821, test accuracy: 0.78828365\n",
      "step: 444, train loss: 0.3074397, train accuracy: 0.9375\n",
      "step: 444, test loss: 0.59517884, test accuracy: 0.76156217\n",
      "step: 448, train loss: 0.1350488, train accuracy: 1.0\n",
      "step: 448, test loss: 0.68395835, test accuracy: 0.7307297\n",
      "step: 452, train loss: 0.25961196, train accuracy: 0.84375\n",
      "step: 452, test loss: 0.646496, test accuracy: 0.76567316\n",
      "step: 456, train loss: 0.22237854, train accuracy: 0.9375\n",
      "step: 456, test loss: 0.62802976, test accuracy: 0.77286744\n",
      "step: 460, train loss: 0.48701316, train accuracy: 0.75\n",
      "step: 460, test loss: 0.75568247, test accuracy: 0.70606375\n",
      "step: 464, train loss: 0.3952176, train accuracy: 0.84375\n",
      "step: 464, test loss: 0.744624, test accuracy: 0.700925\n",
      "step: 468, train loss: 0.4974059, train accuracy: 0.78125\n",
      "step: 468, test loss: 0.62288874, test accuracy: 0.7553957\n",
      "step: 472, train loss: 0.3857836, train accuracy: 0.875\n",
      "step: 472, test loss: 0.5801187, test accuracy: 0.76567316\n",
      "step: 476, train loss: 0.35561138, train accuracy: 0.8125\n",
      "step: 476, test loss: 0.5999135, test accuracy: 0.7595067\n",
      "step: 480, train loss: 0.21358532, train accuracy: 0.96875\n",
      "step: 480, test loss: 0.7040223, test accuracy: 0.7122302\n",
      "step: 484, train loss: 0.16972032, train accuracy: 0.90625\n",
      "step: 484, test loss: 0.60484606, test accuracy: 0.7759507\n",
      "step: 488, train loss: 0.25457326, train accuracy: 0.90625\n",
      "step: 488, test loss: 0.6575321, test accuracy: 0.78006166\n",
      "step: 492, train loss: 0.1365658, train accuracy: 1.0\n",
      "step: 492, test loss: 0.78650385, test accuracy: 0.7410072\n",
      "step: 496, train loss: 0.32253838, train accuracy: 0.90625\n",
      "step: 496, test loss: 0.66546476, test accuracy: 0.7903392\n"
     ]
    }
   ],
   "source": [
    "# batch training\n",
    "test_X, test_y, test_seqlen, test_aspects = u.getData('test')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        batch_X, batch_y, batch_seqlen, batch_aspects = u.nextBatch(batch_size)\n",
    "        sess.run(optimizer, feed_dict = {X: batch_X, y: batch_y, seqlen: batch_seqlen, aspects: batch_aspects})\n",
    "        if i > 0 and i % 4 == 0:\n",
    "            loss_train, accuracy_train = sess.run([loss, accuracy], feed_dict = {X: batch_X, y: batch_y, seqlen: batch_seqlen, aspects: batch_aspects})\n",
    "            print('step: %s, train loss: %s, train accuracy: %s' % (i, loss_train, accuracy_train))\n",
    "            loss_test, accuracy_test = sess.run([loss, accuracy], feed_dict = {X: test_X, y: test_y, seqlen: test_seqlen, aspects: test_aspects})\n",
    "            print('step: %s, test loss: %s, test accuracy: %s' % (i, loss_test, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
